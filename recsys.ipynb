{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b51f784-ab11-4b89-9855-a0665e2fcdcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q tensorflow-recommenders\n",
    "!pip install -q plotnine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d084ff1-e153-4f63-a4c7-daa561ce028c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_USE_LEGACY_KERAS'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c4e9d9f-5742-473a-8a3a-5053d46538fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-20 00:00:22.116778: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import joblib\n",
    "\n",
    "import datetime\n",
    "\n",
    "from typing import List, Union, Dict, Text\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import tensorflow as tf \n",
    "import tensorflow_recommenders as tfrs \n",
    "\n",
    "import plotnine\n",
    "import gdown "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24abdeea-7e7c-4453-aba5-19bde9f89c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_location = 's3://w210recsys/processed/books_data_clean.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff017852-7d34-49f7-a1e0-ffa0c0d8a537",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(data_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "70ce3126-45dc-4559-b0f9-71003147144a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>title</th>\n",
       "      <th>standard_title</th>\n",
       "      <th>authors</th>\n",
       "      <th>primary_author</th>\n",
       "      <th>categories</th>\n",
       "      <th>parsed_categories</th>\n",
       "      <th>category_cluster</th>\n",
       "      <th>publish_year</th>\n",
       "      <th>review_helpfulness</th>\n",
       "      <th>review_score</th>\n",
       "      <th>review_time</th>\n",
       "      <th>review_summary</th>\n",
       "      <th>review_text</th>\n",
       "      <th>description</th>\n",
       "      <th>embedding_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0826414346</td>\n",
       "      <td>A30TK6U7DNS82R</td>\n",
       "      <td>Dr. Seuss: American Icon</td>\n",
       "      <td>dr seuss american icon</td>\n",
       "      <td>['Philip Nel']</td>\n",
       "      <td>Philip Nel</td>\n",
       "      <td>['Biography &amp; Autobiography']</td>\n",
       "      <td>[Biography &amp; Autobiography]</td>\n",
       "      <td>Cluster 5: ['History', 'Biography &amp; Autobiogra...</td>\n",
       "      <td>2005</td>\n",
       "      <td>10</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2004-09-21</td>\n",
       "      <td>Really Enjoyed It</td>\n",
       "      <td>I don't care much for Dr. Seuss but after read...</td>\n",
       "      <td>Philip Nel takes a fascinating look into the k...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0826414346</td>\n",
       "      <td>A2MVUWT453QH61</td>\n",
       "      <td>Dr. Seuss: American Icon</td>\n",
       "      <td>dr seuss american icon</td>\n",
       "      <td>['Philip Nel']</td>\n",
       "      <td>Philip Nel</td>\n",
       "      <td>['Biography &amp; Autobiography']</td>\n",
       "      <td>[Biography &amp; Autobiography]</td>\n",
       "      <td>Cluster 5: ['History', 'Biography &amp; Autobiogra...</td>\n",
       "      <td>2005</td>\n",
       "      <td>7</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2004-07-25</td>\n",
       "      <td>Phlip Nel gives silly Seuss a serious treatment</td>\n",
       "      <td>Theodore Seuss Geisel (1904-1991), aka &amp;quot;D...</td>\n",
       "      <td>Philip Nel takes a fascinating look into the k...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0826414346</td>\n",
       "      <td>A2F6NONFUDB6UK</td>\n",
       "      <td>Dr. Seuss: American Icon</td>\n",
       "      <td>dr seuss american icon</td>\n",
       "      <td>['Philip Nel']</td>\n",
       "      <td>Philip Nel</td>\n",
       "      <td>['Biography &amp; Autobiography']</td>\n",
       "      <td>[Biography &amp; Autobiography]</td>\n",
       "      <td>Cluster 5: ['History', 'Biography &amp; Autobiogra...</td>\n",
       "      <td>2005</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2005-09-20</td>\n",
       "      <td>One of America's greatest creative talents</td>\n",
       "      <td>\"Dr. Seuss: American Icon\" by Philip Nel is a ...</td>\n",
       "      <td>Philip Nel takes a fascinating look into the k...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0826414346</td>\n",
       "      <td>A14OJS0VWMOSWO</td>\n",
       "      <td>Dr. Seuss: American Icon</td>\n",
       "      <td>dr seuss american icon</td>\n",
       "      <td>['Philip Nel']</td>\n",
       "      <td>Philip Nel</td>\n",
       "      <td>['Biography &amp; Autobiography']</td>\n",
       "      <td>[Biography &amp; Autobiography]</td>\n",
       "      <td>Cluster 5: ['History', 'Biography &amp; Autobiogra...</td>\n",
       "      <td>2005</td>\n",
       "      <td>3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2004-11-11</td>\n",
       "      <td>A memorably excellent survey of Dr. Seuss' man...</td>\n",
       "      <td>Theodor Seuss Giesel was best known as 'Dr. Se...</td>\n",
       "      <td>Philip Nel takes a fascinating look into the k...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0829814000</td>\n",
       "      <td>A373VVEU6Z9M0N</td>\n",
       "      <td>Wonderful Worship in Smaller Churches</td>\n",
       "      <td>wonderful worship in smaller churches</td>\n",
       "      <td>['David R. Ray']</td>\n",
       "      <td>David R. Ray</td>\n",
       "      <td>['Religion']</td>\n",
       "      <td>[Religion]</td>\n",
       "      <td>Cluster 16: ['Religion', 'Christian life', 'Ch...</td>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2010-12-08</td>\n",
       "      <td>Small Churches CAN Have Wonderful Worship</td>\n",
       "      <td>Many small churches feel like they can not hav...</td>\n",
       "      <td>This resource includes twelve principles in un...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id         user_id                                  title  \\\n",
       "0   0826414346  A30TK6U7DNS82R               Dr. Seuss: American Icon   \n",
       "2   0826414346  A2MVUWT453QH61               Dr. Seuss: American Icon   \n",
       "4   0826414346  A2F6NONFUDB6UK               Dr. Seuss: American Icon   \n",
       "5   0826414346  A14OJS0VWMOSWO               Dr. Seuss: American Icon   \n",
       "10  0829814000  A373VVEU6Z9M0N  Wonderful Worship in Smaller Churches   \n",
       "\n",
       "                           standard_title           authors primary_author  \\\n",
       "0                  dr seuss american icon    ['Philip Nel']     Philip Nel   \n",
       "2                  dr seuss american icon    ['Philip Nel']     Philip Nel   \n",
       "4                  dr seuss american icon    ['Philip Nel']     Philip Nel   \n",
       "5                  dr seuss american icon    ['Philip Nel']     Philip Nel   \n",
       "10  wonderful worship in smaller churches  ['David R. Ray']   David R. Ray   \n",
       "\n",
       "                       categories            parsed_categories  \\\n",
       "0   ['Biography & Autobiography']  [Biography & Autobiography]   \n",
       "2   ['Biography & Autobiography']  [Biography & Autobiography]   \n",
       "4   ['Biography & Autobiography']  [Biography & Autobiography]   \n",
       "5   ['Biography & Autobiography']  [Biography & Autobiography]   \n",
       "10                   ['Religion']                   [Religion]   \n",
       "\n",
       "                                     category_cluster  publish_year  \\\n",
       "0   Cluster 5: ['History', 'Biography & Autobiogra...          2005   \n",
       "2   Cluster 5: ['History', 'Biography & Autobiogra...          2005   \n",
       "4   Cluster 5: ['History', 'Biography & Autobiogra...          2005   \n",
       "5   Cluster 5: ['History', 'Biography & Autobiogra...          2005   \n",
       "10  Cluster 16: ['Religion', 'Christian life', 'Ch...          2000   \n",
       "\n",
       "   review_helpfulness  review_score review_time  \\\n",
       "0                  10           5.0  2004-09-21   \n",
       "2                   7           4.0  2004-07-25   \n",
       "4                   2           4.0  2005-09-20   \n",
       "5                   3           5.0  2004-11-11   \n",
       "10                  1           5.0  2010-12-08   \n",
       "\n",
       "                                       review_summary  \\\n",
       "0                                   Really Enjoyed It   \n",
       "2     Phlip Nel gives silly Seuss a serious treatment   \n",
       "4          One of America's greatest creative talents   \n",
       "5   A memorably excellent survey of Dr. Seuss' man...   \n",
       "10          Small Churches CAN Have Wonderful Worship   \n",
       "\n",
       "                                          review_text  \\\n",
       "0   I don't care much for Dr. Seuss but after read...   \n",
       "2   Theodore Seuss Geisel (1904-1991), aka &quot;D...   \n",
       "4   \"Dr. Seuss: American Icon\" by Philip Nel is a ...   \n",
       "5   Theodor Seuss Giesel was best known as 'Dr. Se...   \n",
       "10  Many small churches feel like they can not hav...   \n",
       "\n",
       "                                          description  embedding_idx  \n",
       "0   Philip Nel takes a fascinating look into the k...              0  \n",
       "2   Philip Nel takes a fascinating look into the k...              1  \n",
       "4   Philip Nel takes a fascinating look into the k...              2  \n",
       "5   Philip Nel takes a fascinating look into the k...              3  \n",
       "10  This resource includes twelve principles in un...              4  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dbb3f7ef-b540-44a1-b4b3-d2439d7ef068",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(394985, 17)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "54acb90f-9a1a-41ba-b9a2-e83e4b45a990",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9bf30b4b-ea56-4102-bb9d-7cd21faf8b8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/test split files do not exist. Creating them now...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51cafaf5a4464ed6be11c5cc9055dab5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14402 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7090f1ccceb4501b44a07a5239d1cc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14402 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set saved at: s3://w210recsys/book_raw/train_df.csv\n",
      "Test set saved at: s3://w210recsys/book_raw/test_df.csv\n",
      "Training set: (380583, 17)\n",
      "Test set: (14402, 17)\n"
     ]
    }
   ],
   "source": [
    "#### RAM Killer ####\n",
    "# Define file paths (on Google Drive or local path)\n",
    "# train_file_path = \"/home/sagemaker-user/train_df.csv\"\n",
    "# test_file_path = \"/home/sagemaker-user/test_df.csv\"\n",
    "\n",
    "train_file_path = \"s3://w210recsys/book_raw/train_df.csv\"\n",
    "test_file_path = \"s3://w210recsys/book_raw/test_df.csv\"\n",
    "\n",
    "# Check if the train/test files exist\n",
    "if not os.path.exists(train_file_path) or not os.path.exists(test_file_path):\n",
    "    print(\"Train/test split files do not exist. Creating them now...\")\n",
    "\n",
    "    # Sort the dataframe by user_id and timestamp\n",
    "    ratings_df = df.sort_values(by=['user_id', 'review_time'])\n",
    "\n",
    "    # Create train/test splits using groupby and apply with progress bar\n",
    "    train_df = df.groupby('user_id').progress_apply(lambda x: x.iloc[:-1]).reset_index(drop=True)\n",
    "    test_df = df.groupby('user_id').progress_apply(lambda x: x.iloc[-1:]).reset_index(drop=True)\n",
    "\n",
    "    # Save the splits to CSV files on Google Drive\n",
    "    train_df.to_csv(train_file_path, index=False)\n",
    "    test_df.to_csv(test_file_path, index=False)\n",
    "\n",
    "    print(f\"Training set saved at: {train_file_path}\")\n",
    "    print(f\"Test set saved at: {test_file_path}\")\n",
    "else:\n",
    "    print(f\"Train/test split files already exist. Loading them...\")\n",
    "\n",
    "    # Load the saved train/test splits from CSV files\n",
    "    train_df = pd.read_csv(train_file_path)\n",
    "    test_df = pd.read_csv(test_file_path)\n",
    "\n",
    "# Check the sizes of the datasets\n",
    "print(f\"Training set: {train_df.shape}\")\n",
    "print(f\"Test set: {test_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "66614246-1ecf-4ca0-b0e7-58d6cedf90bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'user_id': b'A01038432MVI9JXYTTK5T', 'title': b'Journey to the Centre of the Earth', 'review_score': 5.0}\n",
      "{'user_id': b'A01038432MVI9JXYTTK5T', 'title': b'Twenty thousand leagues under the sea', 'review_score': 5.0}\n",
      "{'user_id': b'A01038432MVI9JXYTTK5T', 'title': b'20, 000 Leagues Under the Sea', 'review_score': 5.0}\n",
      "{'user_id': b'A01038432MVI9JXYTTK5T', 'title': b'Twenty Thousand Leagues Under the Sea (Thorndike Press Large Print Perennial Bestsellers Series)', 'review_score': 5.0}\n",
      "{'user_id': b'A01038432MVI9JXYTTK5T', 'title': b'Journey to the Center of the Earth', 'review_score': 5.0}\n",
      "\n",
      "\n",
      "{'user_id': b'A01038432MVI9JXYTTK5T', 'title': b'The Mysterious Island (Classics Illustrated)', 'review_score': 5.0}\n",
      "{'user_id': b'A100NGGXRQF0AQ', 'title': b'Repressed Memories: A Journey to Recovery from Sexual Abuse (Fireside Parkside Books)', 'review_score': 2.0}\n",
      "{'user_id': b'A100V1W0C8BWOL', 'title': b'The Scarlet Letter, A Romance', 'review_score': 4.0}\n",
      "{'user_id': b'A100YHBWL4TR4D', 'title': b'Tea Rose', 'review_score': 5.0}\n",
      "{'user_id': b'A101446I5AWY0Z', 'title': b'Citizens: A Chronicle of the French Revolution', 'review_score': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-20 00:01:34.416098: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2025-02-20 00:01:34.429405: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "# Convert datasets into tensor datasets\n",
    "train_ds = tf.data.Dataset.from_tensor_slices(dict(train_df[['user_id', 'title', 'review_score']]))\n",
    "\n",
    "for x in train_ds.take(5).as_numpy_iterator():\n",
    "    print(x)\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "test_ds = tf.data.Dataset.from_tensor_slices(dict(test_df[['user_id', 'title', 'review_score']]))\n",
    "\n",
    "for x in test_ds.take(5).as_numpy_iterator():\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2bd6951d-f233-4db6-88db-4dbb965f5fbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'title': b'Journey to the Centre of the Earth'}\n",
      "{'title': b'Twenty thousand leagues under the sea'}\n",
      "{'title': b'20, 000 Leagues Under the Sea'}\n",
      "{'title': b'Twenty Thousand Leagues Under the Sea (Thorndike Press Large Print Perennial Bestsellers Series)'}\n",
      "{'title': b'Journey to the Center of the Earth'}\n"
     ]
    }
   ],
   "source": [
    "# Create Feature Vocabularies\n",
    "unique_user_ids = train_df['user_id'].unique()\n",
    "unique_titles = train_df['title'].unique()\n",
    "unique_review_scores = train_df['review_score'].unique()\n",
    "\n",
    "# Candidates for retrieval Task\n",
    "candidate_ds = tf.data.Dataset.from_tensor_slices(dict(\n",
    "    train_df[['title']].drop_duplicates()\n",
    "))\n",
    "\n",
    "for x in candidate_ds.take(5).as_numpy_iterator():\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "09d21c38-9e79-4913-9dc1-6c3a97bbb806",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70874"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unique_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0c74b246-f84d-47e0-8d3d-457618bd2342",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cache train dataset & Candidate dataset\n",
    "train_size = train_df.shape[0]\n",
    "cached_train = train_ds.shuffle(train_size).batch(128).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "750820b5-3e37-4fd2-a8e4-fb452dc13a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# User/Query Model\n",
    "class UserModel(tf.keras.Model):\n",
    "    '''\n",
    "    The user(query) tower\n",
    "    '''\n",
    "\n",
    "    def __init__(self,\n",
    "                 unique_user_ids: np.ndarray,\n",
    "                 feature_user_id_name: str,\n",
    "                 embedding_dimensions: int):\n",
    "        '''\n",
    "        Params\n",
    "        :param unique_user_ids: array of unique user ids\n",
    "        :param feature_user_id_name: name of the feature\n",
    "        :param embedding_dimension: number of dimensions in embedding layer\n",
    "        '''\n",
    "        super().__init__()\n",
    "        self.feature_user_id_name = feature_user_id_name\n",
    "\n",
    "        self.user_embedding_layers = tf.keras.Sequential(\n",
    "            [\n",
    "                tf.keras.layers.StringLookup(\n",
    "                    vocabulary=unique_user_ids,\n",
    "                    mask_token=None,\n",
    "                    name='user_id_vocab',\n",
    "                ),\n",
    "                tf.keras.layers.Embedding(\n",
    "                    input_dim=len(unique_user_ids) + 1,\n",
    "                    output_dim=embedding_dimensions,\n",
    "                    name='user_id_embedding',\n",
    "                ),\n",
    "            ],\n",
    "        )\n",
    "\n",
    "    def call(self, inputs: Dict[Text, tf.Tensor]) -> tf.Tensor:\n",
    "        return self.user_embedding_layers(inputs[self.feature_user_id_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3a7d5302-8820-462b-81da-9930247d6c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BookModel(tf.keras.Model):\n",
    "    '''\n",
    "    The book(query) tower\n",
    "    '''\n",
    "\n",
    "    def __init__(self,\n",
    "                 unique_titles: np.ndarray,\n",
    "                 feature_book_title_name: str,\n",
    "                 embedding_dimensions: int,\n",
    "                 text_vectorization_max_tokens: int):\n",
    "        '''\n",
    "        Params\n",
    "        :param unique_titles: array of unique titles\n",
    "        :param unique_review_scores: array of unique review scores\n",
    "        :param feature_book_title_name: name of the column title\n",
    "        :param embedding_dimensions: number of dimensions in embedding layer\n",
    "        :param text_vectorization_max_tokens: maximum number of tokens to vector\n",
    "        '''\n",
    "        super().__init__()\n",
    "        self.feature_book_title_name = feature_book_title_name\n",
    "\n",
    "        # Book Title embedding\n",
    "        self.book_embedding_layers = tf.keras.Sequential(\n",
    "            [\n",
    "                tf.keras.layers.StringLookup(\n",
    "                    vocabulary=unique_titles,\n",
    "                    mask_token=None,\n",
    "                    name='book_id_vocab',\n",
    "                ),\n",
    "                tf.keras.layers.Embedding(\n",
    "                    input_dim=len(unique_titles) + 1,\n",
    "                    output_dim=embedding_dimensions,\n",
    "                    name='book_id_embedding',\n",
    "                ),\n",
    "            ],\n",
    "            name='book_id_embedding',\n",
    "        )\n",
    "\n",
    "    def call(self, inputs: Dict[Text, tf.Tensor]) -> tf.Tensor:\n",
    "        return tf.concat([\n",
    "            self.book_embedding_layers(inputs[self.feature_book_title_name]),\n",
    "            # add more embedding layers as needed\n",
    "        ], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a53e9482-ca65-40c9-9b22-7e4779f57641",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BooksTwoTowersModel(tfrs.Model):\n",
    "    '''\n",
    "    Two-Towers books recommender model\n",
    "    '''\n",
    "    def __init__(self,\n",
    "                 unique_user_ids: np.ndarray,\n",
    "                 unique_titles: np.ndarray,\n",
    "                 unique_review_scores: np.ndarray,\n",
    "                 candidate_ds: tf.data.Dataset,\n",
    "                 feature_user_id_name: str = 'user_id',\n",
    "                 feature_book_title_name: str = 'title',\n",
    "                 feature_review_score_name: str = 'review_score',\n",
    "                 embedding_dimensions: int = 64):\n",
    "        '''\n",
    "        Instantiate query tower, candidate tower, and retrieval task.\n",
    "        '''\n",
    "        super().__init__()\n",
    "        self.feature_user_id_name = feature_user_id_name\n",
    "        self.feature_book_title_name = feature_book_title_name\n",
    "        self.feature_review_score_name = feature_review_score_name\n",
    "\n",
    "        # Query Tower\n",
    "        self.user_model = UserModel(\n",
    "            unique_user_ids=unique_user_ids,\n",
    "            feature_user_id_name=feature_user_id_name,\n",
    "            embedding_dimensions=embedding_dimensions,\n",
    "        )\n",
    "\n",
    "        # Candidate Tower\n",
    "        text_vectorization_max_tokens = len(unique_titles) + len(unique_review_scores)\n",
    "\n",
    "        book_model_raw = BookModel(\n",
    "            unique_titles=unique_titles,\n",
    "            feature_book_title_name=feature_book_title_name,\n",
    "            embedding_dimensions=embedding_dimensions,\n",
    "            text_vectorization_max_tokens=text_vectorization_max_tokens,\n",
    "        )\n",
    "\n",
    "        # Dense projection layer to equate final tower output dims\n",
    "        self.book_model = tf.keras.Sequential(\n",
    "            [\n",
    "                book_model_raw,\n",
    "                tf.keras.layers.Dense(\n",
    "                    units=embedding_dimensions,\n",
    "                    name='book_dense_projection',\n",
    "                ),\n",
    "            ],\n",
    "            name='book_sequential',\n",
    "        )\n",
    "\n",
    "        # Retrieval Task\n",
    "        self.task = tfrs.tasks.Retrieval(\n",
    "            metrics=tfrs.metrics.FactorizedTopK(\n",
    "                candidates=candidate_ds.batch(128).map(self.book_model),\n",
    "                ks=(10, 20, 50)\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def compute_loss(self,\n",
    "                     features: Dict[Text, tf.Tensor],\n",
    "                     training=False) -> tf.Tensor:\n",
    "        '''\n",
    "        Get embeddings for users and books.\n",
    "        Compute dot product and retrieve candidates.\n",
    "        '''\n",
    "        user_embeddings = self.user_model({\n",
    "            self.feature_user_id_name: features[self.feature_user_id_name],\n",
    "        })\n",
    "\n",
    "        book_embeddings = self.book_model({\n",
    "            self.feature_book_title_name: features[self.feature_book_title_name],\n",
    "        })\n",
    "\n",
    "        # Sample weight logic\n",
    "        review_scores = tf.cast(features[self.feature_review_score_name], tf.float32)\n",
    "        sample_weight = tf.where(review_scores >= 4, 1.0, 0.0)\n",
    "\n",
    "        return self.task(user_embeddings, book_embeddings, compute_metrics=not training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dc207cd2-1681-4aa2-9498-6001d4c9621a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup log dir for tensorboard\n",
    "LOG_DIR = \"/home/sagemaker-user/logs\"\n",
    "\n",
    "if not os.path.exists(LOG_DIR):\n",
    "    os.makedirs(LOG_DIR)\n",
    "\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=LOG_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a441bb1a-0339-4393-82fd-80943e67f7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile Model\n",
    "model = BooksTwoTowersModel(\n",
    "    unique_user_ids=unique_user_ids,\n",
    "    unique_titles=unique_titles,\n",
    "    unique_review_scores=unique_review_scores,\n",
    "    candidate_ds=candidate_ds,\n",
    "    embedding_dimensions=64,\n",
    ")\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(learning_rate=0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0e3f9b36-d38f-4f69-87ab-b07918332c9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2974/2974 [==============================] - 8s 2ms/step - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_20_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - loss: 555.9264 - regularization_loss: 0.0000e+00 - total_loss: 555.9264\n",
      "Epoch 2/10\n",
      "2974/2974 [==============================] - 6s 2ms/step - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_20_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - loss: 410.4477 - regularization_loss: 0.0000e+00 - total_loss: 410.4477\n",
      "Epoch 3/10\n",
      "2974/2974 [==============================] - 6s 2ms/step - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_20_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - loss: 293.7381 - regularization_loss: 0.0000e+00 - total_loss: 293.7381\n",
      "Epoch 4/10\n",
      "2974/2974 [==============================] - 6s 2ms/step - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_20_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - loss: 224.9130 - regularization_loss: 0.0000e+00 - total_loss: 224.9130\n",
      "Epoch 5/10\n",
      "2974/2974 [==============================] - 6s 2ms/step - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_20_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - loss: 185.6363 - regularization_loss: 0.0000e+00 - total_loss: 185.6363\n",
      "Epoch 6/10\n",
      "2974/2974 [==============================] - 6s 2ms/step - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_20_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - loss: 160.9045 - regularization_loss: 0.0000e+00 - total_loss: 160.9045\n",
      "Epoch 7/10\n",
      "2974/2974 [==============================] - 6s 2ms/step - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_20_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - loss: 143.9904 - regularization_loss: 0.0000e+00 - total_loss: 143.9904\n",
      "Epoch 8/10\n",
      "2974/2974 [==============================] - 6s 2ms/step - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_20_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - loss: 131.6619 - regularization_loss: 0.0000e+00 - total_loss: 131.6619\n",
      "Epoch 9/10\n",
      "2974/2974 [==============================] - 6s 2ms/step - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_20_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - loss: 122.1203 - regularization_loss: 0.0000e+00 - total_loss: 122.1203\n",
      "Epoch 10/10\n",
      "2974/2974 [==============================] - 6s 2ms/step - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_20_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - loss: 114.5570 - regularization_loss: 0.0000e+00 - total_loss: 114.5570\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf_keras.src.callbacks.History at 0x7faa2e0eb6d0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train\n",
    "model.fit(\n",
    "    cached_train,\n",
    "    epochs=10,\n",
    "    callbacks=[tensorboard_callback],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5a1f15-f961-4c72-ac78-1084ef872361",
   "metadata": {},
   "outputs": [],
   "source": [
    "book_embeddings = model.book_model.layers[0].book_embedding_layers.get_weights()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3528799b-b601-4390-99a4-6208ccd070d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_embeddings = model.user_model.user_embedding_layers.get_weights()[0]\n",
    "user_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05f6cb3-8983-4710-ba19-66cf80d48118",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826ff9c7-f4a0-457b-9387-60e02a357c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_user = tf.data.Dataset.from_tensor_slices({\n",
    "    'user_id': test_df['user_id'].sample(1).values,\n",
    "    'title': test_df['title'].sample(1).values,\n",
    "    'review_score': test_df['review_score'].sample(1).values,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a577b0-49c2-42c5-b901-3a52d39a414e",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_embeddings = model.user_model.predict(test_user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfcb738d-742e-4e1e-9346-734b71fbbff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_embeddings.shape == book_embeddings[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42228cb-efb7-4362-a699-9dbfd10b1fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "book_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa1687e-fc53-40b7-b016-091c9edc670a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ade909-607b-4c8c-8563-b3ca61b587b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_embeddings_2d = np.expand_dims(user_embeddings, axis=0)\n",
    "cosine_sim = cosine_similarity(user_embeddings_2d, book_embeddings)\n",
    "cosine_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010af76c-7bd0-46e3-bb87-3d1ad095644e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cosine_sim[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e279ae57-96b9-4cec-905b-34fb3083806a",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_n = 10\n",
    "top_n_indicies = np.argsort(cosine_sim[0])[::-1][:top_n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17730fef-6e7c-4897-90d7-57a882d5500b",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_n_indicies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1674bec2-59b0-43d1-a758-25deb7d17665",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in top_n_indicies:\n",
    "    print(unique_titles[i-1])\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f6824b-9561-4cf0-8ecb-951e900a4763",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fasten Your Seat Belts! History and Heroism in the Pan Am Cabin\n",
    "\n",
    "# Twice Loved\n",
    "\n",
    "# Agent of Vega\n",
    "\n",
    "# Pagan Heat\n",
    "\n",
    "# Freedom's Price (Loveswept)\n",
    "\n",
    "# Looneyspoons: Low-Fat Food Made Fun!\n",
    "\n",
    "# The Bluebird and the Sparrow (Women of the West #10) (Janette Oke Classics for Girls)\n",
    "\n",
    "# How to Start a Business in New York City\n",
    "\n",
    "# Transmitter Hunting: Radio Direction Finding Simplified\n",
    "\n",
    "# The Staircase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92bea429-4adc-4ac2-9bde-9b402bfb91c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "row=unique_titles[6892]\n",
    "row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccea70f2-50ac-4f5f-a2bd-d811eea21725",
   "metadata": {},
   "outputs": [],
   "source": [
    "# '''\n",
    "# Params\n",
    "# :param unique_titles: array of unique titles\n",
    "# :param unique_review_scores: array of unique review scores\n",
    "# :param feature_book_title_name: name of the column title\n",
    "# :param embedding_dimensions: number of dimensions in embedding layer\n",
    "# :param text_vectorization_max_tokens: maximum number of tokens to vector\n",
    "# '''\n",
    "t = []\n",
    "r = []\n",
    "t.append(df.title.iloc[1])\n",
    "r.append(df.review_score.iloc[1])\n",
    "# r = list(df.review_score.iloc[1])\n",
    "c = 'title'\n",
    "d = 64\n",
    "v = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e630da5b-315f-4fad-80e9-e23f59c2fa41",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SageModel(\n",
    "    model=inference.py\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
